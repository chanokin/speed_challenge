{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_generators import *\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda, SpatialDropout2D\n",
    "from keras.layers import Conv2D, ELU\n",
    "from keras.optimizers import rmsprop, Adam\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# SpatialDropout2D <==> data_format='channels_last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2879432174968659316, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11323454260\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 16125217443312319976\n",
       " physical_device_desc: \"device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE, ROWS, COLS, CHANNELS = 32, 480, 640, 4\n",
    "\n",
    "#inspired in https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "def cnn_model():\n",
    "    in_shape = (ROWS, COLS, CHANNELS)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (7, 7), padding='valid', \n",
    "                     kernel_initializer='lecun_uniform',\n",
    "                     strides=(2,2), input_shape=in_shape)\n",
    "    )\n",
    "    model.add(ELU())\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(48, (5, 5), padding='valid', \n",
    "                     kernel_initializer='lecun_uniform',\n",
    "                     strides=(2,2))\n",
    "    )\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(SpatialDropout2D(0.5))\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5), padding='valid', \n",
    "                     kernel_initializer='lecun_uniform',\n",
    "                     strides=(2,2))\n",
    "    )\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='valid', \n",
    "                     kernel_initializer='lecun_uniform',\n",
    "                     strides=(2,2))\n",
    "    )\n",
    "    model.add(ELU())\n",
    "\n",
    "#     model.add(SpatialDropout2D(0.5))\n",
    "    \n",
    "#     model.add(Conv2D(128, (3, 3), padding='valid', \n",
    "#                      kernel_initializer='lecun_uniform',\n",
    "#                      strides=(2,2))\n",
    "#     )\n",
    "#     model.add(ELU())\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256))\n",
    "    model.add(ELU())\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(ELU())\n",
    "#     model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "#     optimizer = rmsprop(lr=0.0001, decay=1e-6)\n",
    "    optimizer = Adam(\n",
    "#         lr=0.001, \n",
    "#         beta_1=0.9, \n",
    "#         beta_2=0.999, \n",
    "#         epsilon=None, \n",
    "#         decay=0.0, \n",
    "        amsgrad=bool(1)\n",
    "    )\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16319 3875 203\n"
     ]
    }
   ],
   "source": [
    "thresh = 0.05\n",
    "suffix = \"%03dp\"%(np.round(100.0*thresh))\n",
    "train_files = sorted(glob.glob('./train_%s/*.npz'%suffix))\n",
    "total_n_train = len(train_files)\n",
    "\n",
    "# test_files = sorted(glob.glob('./test/*.npz'))\n",
    "\n",
    "n_train, n_valid, n_test = int(0.8*total_n_train), int(0.19*total_n_train), int(0.01*total_n_train)\n",
    "\n",
    "print(n_train, n_valid, n_test)\n",
    "train_steps = int(np.ceil(float(n_train) / float(BATCH_SIZE)))\n",
    "valid_steps = int(np.ceil(float(n_valid) / float(BATCH_SIZE)))\n",
    "test_steps = int(np.ceil(float(n_test) / float(BATCH_SIZE)))\n",
    "\n",
    "train_ids = np.random.choice(total_n_train, size=n_train, replace=False)\n",
    "avail_ids = np.setdiff1d(np.arange(total_n_train), train_ids)\n",
    "test_ids = np.random.choice(avail_ids, size=n_test, replace=False)\n",
    "valid_ids = np.setdiff1d(avail_ids, test_ids)\n",
    "\n",
    "train_data = [train_files[i] for i in train_ids]\n",
    "valid_data = [train_files[i] for i in valid_ids]\n",
    "test_data = [train_files[i] for i in test_ids]\n",
    "\n",
    "train_gen = train_generator(train_data, BATCH_SIZE)\n",
    "valid_gen = train_generator(valid_data, BATCH_SIZE)\n",
    "test_gen = train_generator(test_data, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'training_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "model_fname = os.path.join(output_dir, 'best_val_model_%s.h5'%suffix)\n",
    "mc = ModelCheckpoint(model_fname, monitor='val_loss', \n",
    "                     mode='min', save_best_only=True)\n",
    "\n",
    "model_fname = os.path.join(output_dir, 'best_train_model_%s.h5'%suffix)\n",
    "mc = ModelCheckpoint(model_fname, monitor='loss', \n",
    "                     mode='min', save_best_only=True)\n",
    "\n",
    "# test_gen = test_generator(test_files, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "509/510 [============================>.] - ETA: 0s - loss: 32.2832"
     ]
    }
   ],
   "source": [
    "fit_log = model.fit_generator(\n",
    "    train_gen, \n",
    "    steps_per_epoch=train_steps, \n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=valid_steps,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "history_fname = os.path.join(output_dir, 'train_history_dict.pickle')\n",
    "with open(history_fname, 'wb') as file_pi:\n",
    "        pickle.dump(fit_log.history, file_pi)\n",
    "        \n",
    "\n",
    "model_fname = os.path.join(output_dir, 'speed_test_model_%s.h5'%suffix)\n",
    "model.save(model_fname)\n",
    "\n",
    "#scores = model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('training_output', exist_ok=True)\n",
    "model_fname = os.path.join('training_output', 'speed_test_model.h5')\n",
    "model = load_model(model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_gen, steps=test_steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.plot(fit_log.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.plot(fit_log.history['loss'])\n",
    "plt.plot(fit_log.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.summary())\n",
    "print(model.weights)\n",
    "# plt.figure()\n",
    "# plt.plot(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
