{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_generators import *\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.convolutional import Convolution2D, Convolution3D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda, SpatialDropout2D\n",
    "from keras.layers import Conv2D, ELU, Conv3D, MaxPooling2D\n",
    "from keras.optimizers import rmsprop, Adam\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.regularizers import l2\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "# SpatialDropout2D <==> data_format='channels_last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15307720015515923969, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11323454260\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 15870071728489626574\n",
       " physical_device_desc: \"device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE, ROWS, COLS, CHANNELS = 32, 480, 640, 5\n",
    "# BATCH_SIZE, ROWS, COLS, CHANNELS = 32, 480, 640, 3\n",
    "BATCH_SIZE, ROWS, COLS, CHANNELS = 32, 480, 640, 2\n",
    "\n",
    "#inspired in https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "#https://medium.com/weightsandbiases/predicting-vehicle-speed-from-dashcam-video-f6158054f6fd\n",
    "class Residual(Layer):\n",
    "    def __init__(self, channels_in, kernel,**kwargs):\n",
    "        super(Residual, self).__init__(**kwargs)\n",
    "        self.channels_in = channels_in\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def call(self, x):\n",
    "        # the residual block using Keras functional API\n",
    "        first_layer =   Activation(\"linear\", trainable=False)(x)\n",
    "        x =             Conv2D( self.channels_in,\n",
    "                                self.kernel,\n",
    "                                padding=\"same\")(first_layer)\n",
    "        x =             Activation(\"elu\")(x)\n",
    "        x =             Conv2D( self.channels_in,\n",
    "                                self.kernel,\n",
    "                                padding=\"same\")(x)\n",
    "        residual =      Add()([x, first_layer])\n",
    "        x =             Activation(\"elu\")(residual)\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "def cnn_model():\n",
    "    kernel_init='lecun_normal'\n",
    "    initializer='he_normal'\n",
    "    in_shape = (ROWS, COLS, CHANNELS)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (7, 7), padding='valid', \n",
    "                 kernel_initializer=kernel_init,\n",
    "#                  kernel_regularizer=l2(1e-4),\n",
    "                 strides=(3,3), input_shape=in_shape)\n",
    "    )\n",
    "    model.add(ELU())\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(48, (7, 7), padding='valid', \n",
    "                     kernel_initializer=kernel_init,\n",
    "#                      kernel_regularizer=l2(1e-4),\n",
    "                     strides=(3,3))\n",
    "    )\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(SpatialDropout2D(0.5))\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5), padding='valid', \n",
    "                     kernel_initializer=kernel_init,\n",
    "#                      kernel_regularizer=l2(1e-4),\n",
    "                     strides=(2,2))\n",
    "    )\n",
    "    model.add(ELU())\n",
    "\n",
    "#     Residual(32, (7, 7), \n",
    "#         kernel_initializer=kernel_init, \n",
    "#         kernel_regularizer=l2(1e-4),\n",
    "#         input_shape=in_shape\n",
    "#     )\n",
    "\n",
    "#     Residual(64, (5, 5),\n",
    "# #         kernel_initializer=kernel_init, \n",
    "# #         kernel_regularizer=l2(1e-4),\n",
    "#     )\n",
    "    \n",
    "#     model.add(SpatialDropout2D(0.5))\n",
    "    \n",
    "#     Residual(64, (3, 3),\n",
    "# #         kernel_initializer=kernel_init, \n",
    "# #         kernel_regularizer=l2(1e-4),\n",
    "#     )\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5), padding='valid', \n",
    "                     kernel_initializer=kernel_init,\n",
    "#                      kernel_regularizer=l2(1e-4),\n",
    "                     strides=(2,2))\n",
    "    )\n",
    "    model.add(ELU())\n",
    "\n",
    "# #     model.add(SpatialDropout2D(0.5))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='valid', \n",
    "                     kernel_initializer=kernel_init,\n",
    "#                      kernel_regularizer=l2(1e-4),\n",
    "                     strides=(2,2))\n",
    "    )\n",
    "    model.add(ELU())\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256, kernel_initializer=initializer))\n",
    "    model.add(ELU())\n",
    "    \n",
    "#     model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(128, kernel_initializer=initializer))\n",
    "    model.add(ELU())\n",
    "    \n",
    "#     model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(64, kernel_initializer=initializer))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(32, kernel_initializer=initializer))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Dense(1, kernel_initializer=initializer))\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = cnn_model()\n",
    "# for layer in model.layers:\n",
    "#     print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010p_-_00_-_epochs_1000\n",
      "16319 3875 203\n",
      "Epoch 1/1000\n",
      "510/510 [==============================] - 516s 1s/step - loss: 209.9801 - val_loss: 206.2988\n",
      "Epoch 2/1000\n",
      "510/510 [==============================] - 497s 975ms/step - loss: 172.9688 - val_loss: 124.8804\n",
      "Epoch 3/1000\n",
      "510/510 [==============================] - 496s 972ms/step - loss: 92.6487 - val_loss: 71.4289\n",
      "Epoch 4/1000\n",
      "510/510 [==============================] - 497s 974ms/step - loss: 76.7655 - val_loss: 68.0936\n",
      "Epoch 5/1000\n",
      "510/510 [==============================] - 502s 985ms/step - loss: 73.7084 - val_loss: 66.1478\n",
      "Epoch 6/1000\n",
      "510/510 [==============================] - 503s 986ms/step - loss: 69.5513 - val_loss: 61.0602\n",
      "Epoch 7/1000\n",
      "510/510 [==============================] - 512s 1s/step - loss: 66.8977 - val_loss: 60.2351\n",
      "Epoch 8/1000\n",
      "510/510 [==============================] - 507s 994ms/step - loss: 64.2638 - val_loss: 58.2146\n",
      "Epoch 9/1000\n",
      "510/510 [==============================] - 510s 1000ms/step - loss: 61.8999 - val_loss: 56.0048\n",
      "Epoch 10/1000\n",
      "510/510 [==============================] - 507s 994ms/step - loss: 59.4563 - val_loss: 53.5843\n",
      "Epoch 11/1000\n",
      "510/510 [==============================] - 507s 993ms/step - loss: 56.4624 - val_loss: 50.4106\n",
      "Epoch 12/1000\n",
      "510/510 [==============================] - 500s 981ms/step - loss: 54.3636 - val_loss: 48.9745\n",
      "Epoch 13/1000\n",
      "510/510 [==============================] - 496s 972ms/step - loss: 52.3578 - val_loss: 45.3436\n",
      "Epoch 14/1000\n",
      "510/510 [==============================] - 496s 972ms/step - loss: 50.5826 - val_loss: 45.6209\n",
      "Epoch 15/1000\n",
      "510/510 [==============================] - 496s 972ms/step - loss: 47.4009 - val_loss: 42.4748\n",
      "Epoch 16/1000\n",
      "510/510 [==============================] - 506s 993ms/step - loss: 44.8387 - val_loss: 42.2990\n",
      "Epoch 17/1000\n",
      "510/510 [==============================] - 507s 994ms/step - loss: 43.5656 - val_loss: 39.3852\n",
      "Epoch 18/1000\n",
      "510/510 [==============================] - 507s 994ms/step - loss: 41.6985 - val_loss: 37.8364\n",
      "Epoch 19/1000\n",
      "510/510 [==============================] - 503s 987ms/step - loss: 39.1607 - val_loss: 34.4645\n",
      "Epoch 20/1000\n",
      "510/510 [==============================] - 502s 984ms/step - loss: 39.4229 - val_loss: 33.1770\n",
      "Epoch 21/1000\n",
      "510/510 [==============================] - 499s 979ms/step - loss: 37.9490 - val_loss: 32.6392\n",
      "Epoch 22/1000\n",
      "510/510 [==============================] - 505s 991ms/step - loss: 36.1617 - val_loss: 30.3786\n",
      "Epoch 23/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 34.8983 - val_loss: 31.2564\n",
      "Epoch 24/1000\n",
      "510/510 [==============================] - 502s 984ms/step - loss: 34.9659 - val_loss: 31.6554\n",
      "Epoch 25/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 34.3499 - val_loss: 28.0085\n",
      "Epoch 26/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 33.6377 - val_loss: 30.7275\n",
      "Epoch 27/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 32.3650 - val_loss: 28.6898\n",
      "Epoch 28/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 32.1208 - val_loss: 26.7122\n",
      "Epoch 29/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 31.4011 - val_loss: 28.2002\n",
      "Epoch 30/1000\n",
      "510/510 [==============================] - 494s 968ms/step - loss: 30.4646 - val_loss: 26.7577\n",
      "Epoch 31/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 31.0303 - val_loss: 27.4402\n",
      "Epoch 32/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 30.7647 - val_loss: 27.1140\n",
      "Epoch 33/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 29.7838 - val_loss: 24.6632\n",
      "Epoch 34/1000\n",
      "510/510 [==============================] - 494s 970ms/step - loss: 30.1229 - val_loss: 24.5037\n",
      "Epoch 35/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 28.9585 - val_loss: 25.7177\n",
      "Epoch 36/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 28.9834 - val_loss: 24.0459\n",
      "Epoch 37/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 28.5730 - val_loss: 25.3689\n",
      "Epoch 38/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 27.9400 - val_loss: 25.3578\n",
      "Epoch 39/1000\n",
      "510/510 [==============================] - 494s 968ms/step - loss: 27.7564 - val_loss: 23.9057\n",
      "Epoch 40/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 28.1679 - val_loss: 23.6619\n",
      "Epoch 41/1000\n",
      "510/510 [==============================] - 494s 968ms/step - loss: 27.1760 - val_loss: 24.2619\n",
      "Epoch 42/1000\n",
      "510/510 [==============================] - 494s 968ms/step - loss: 26.2108 - val_loss: 23.3715\n",
      "Epoch 43/1000\n",
      "510/510 [==============================] - 494s 968ms/step - loss: 26.6561 - val_loss: 21.8436\n",
      "Epoch 44/1000\n",
      "510/510 [==============================] - 493s 967ms/step - loss: 26.5748 - val_loss: 22.4483\n",
      "Epoch 45/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 26.1040 - val_loss: 23.1944\n",
      "Epoch 46/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 25.4604 - val_loss: 22.5356\n",
      "Epoch 47/1000\n",
      "510/510 [==============================] - 494s 970ms/step - loss: 24.9376 - val_loss: 21.3851\n",
      "Epoch 48/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 25.6727 - val_loss: 23.2438\n",
      "Epoch 49/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 24.9205 - val_loss: 22.3415\n",
      "Epoch 50/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 25.3648 - val_loss: 22.6225\n",
      "Epoch 51/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 24.4174 - val_loss: 20.6594\n",
      "Epoch 52/1000\n",
      "510/510 [==============================] - 496s 973ms/step - loss: 24.6946 - val_loss: 22.2141\n",
      "Epoch 53/1000\n",
      "510/510 [==============================] - 496s 972ms/step - loss: 24.2285 - val_loss: 20.5221\n",
      "Epoch 54/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 23.4645 - val_loss: 19.7179\n",
      "Epoch 55/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 24.0327 - val_loss: 19.3695\n",
      "Epoch 56/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 23.7420 - val_loss: 20.6089\n",
      "Epoch 57/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 22.8017 - val_loss: 20.6711\n",
      "Epoch 58/1000\n",
      "510/510 [==============================] - 496s 972ms/step - loss: 23.2067 - val_loss: 19.6464\n",
      "Epoch 59/1000\n",
      "510/510 [==============================] - 496s 972ms/step - loss: 22.5111 - val_loss: 18.6841\n",
      "Epoch 60/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 22.7942 - val_loss: 18.9826\n",
      "Epoch 61/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 22.5548 - val_loss: 19.5334\n",
      "Epoch 62/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 22.5178 - val_loss: 18.1995\n",
      "Epoch 63/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 21.9689 - val_loss: 19.1112\n",
      "Epoch 64/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 21.5110 - val_loss: 19.4525\n",
      "Epoch 65/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 21.6620 - val_loss: 17.8043\n",
      "Epoch 66/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 21.3711 - val_loss: 18.1639\n",
      "Epoch 67/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 21.6842 - val_loss: 17.2339\n",
      "Epoch 68/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 20.3941 - val_loss: 18.7242\n",
      "Epoch 69/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 21.1210 - val_loss: 18.7437\n",
      "Epoch 70/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 20.8685 - val_loss: 18.2834\n",
      "Epoch 71/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 20.6928 - val_loss: 17.7550\n",
      "Epoch 72/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 20.9806 - val_loss: 18.3442\n",
      "Epoch 73/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 20.4355 - val_loss: 18.0045\n",
      "Epoch 74/1000\n",
      "510/510 [==============================] - 496s 974ms/step - loss: 19.9624 - val_loss: 16.8204\n",
      "Epoch 75/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 19.7588 - val_loss: 16.4839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 20.3464 - val_loss: 19.1830\n",
      "Epoch 77/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 19.9065 - val_loss: 16.4260\n",
      "Epoch 78/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 19.2647 - val_loss: 16.9397\n",
      "Epoch 79/1000\n",
      "510/510 [==============================] - 494s 968ms/step - loss: 19.2229 - val_loss: 17.2645\n",
      "Epoch 80/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 19.6036 - val_loss: 16.0566\n",
      "Epoch 81/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 19.3568 - val_loss: 17.3330\n",
      "Epoch 82/1000\n",
      "510/510 [==============================] - 496s 973ms/step - loss: 18.9381 - val_loss: 15.8462\n",
      "Epoch 83/1000\n",
      "510/510 [==============================] - 497s 974ms/step - loss: 18.9136 - val_loss: 15.2480\n",
      "Epoch 84/1000\n",
      "510/510 [==============================] - 496s 973ms/step - loss: 19.0471 - val_loss: 16.9358\n",
      "Epoch 85/1000\n",
      "510/510 [==============================] - 496s 972ms/step - loss: 18.1952 - val_loss: 16.4652\n",
      "Epoch 86/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 18.5743 - val_loss: 15.7354\n",
      "Epoch 87/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 18.2077 - val_loss: 16.5150\n",
      "Epoch 88/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 18.1888 - val_loss: 16.8860\n",
      "Epoch 89/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 17.8673 - val_loss: 15.3422\n",
      "Epoch 90/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 17.8504 - val_loss: 15.0220\n",
      "Epoch 91/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 18.3008 - val_loss: 15.0376\n",
      "Epoch 92/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 18.2524 - val_loss: 15.6634\n",
      "Epoch 93/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 17.9909 - val_loss: 15.9848\n",
      "Epoch 94/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 17.6108 - val_loss: 14.9424\n",
      "Epoch 95/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 17.5593 - val_loss: 15.0016\n",
      "Epoch 96/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 17.1275 - val_loss: 15.0579\n",
      "Epoch 97/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 17.0256 - val_loss: 15.0073\n",
      "Epoch 98/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 17.4489 - val_loss: 14.3247\n",
      "Epoch 99/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 16.7922 - val_loss: 14.8340\n",
      "Epoch 100/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 17.0998 - val_loss: 14.7138\n",
      "Epoch 101/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 16.4864 - val_loss: 14.4728\n",
      "Epoch 102/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 16.3904 - val_loss: 14.1229\n",
      "Epoch 103/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 16.8245 - val_loss: 15.1829\n",
      "Epoch 104/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 17.0197 - val_loss: 14.3916\n",
      "Epoch 105/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 16.8469 - val_loss: 14.8398\n",
      "Epoch 106/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 16.4949 - val_loss: 14.0434\n",
      "Epoch 107/1000\n",
      "510/510 [==============================] - 494s 970ms/step - loss: 16.3227 - val_loss: 13.9595\n",
      "Epoch 108/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 16.5535 - val_loss: 15.1561\n",
      "Epoch 109/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 15.7936 - val_loss: 13.8197\n",
      "Epoch 110/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 16.5456 - val_loss: 13.1131\n",
      "Epoch 111/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 15.9821 - val_loss: 14.5077\n",
      "Epoch 112/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 15.4071 - val_loss: 13.6740\n",
      "Epoch 113/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 15.7627 - val_loss: 15.3087\n",
      "Epoch 114/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 16.2952 - val_loss: 13.3209\n",
      "Epoch 115/1000\n",
      "510/510 [==============================] - 495s 972ms/step - loss: 15.7422 - val_loss: 14.6418\n",
      "Epoch 116/1000\n",
      "510/510 [==============================] - 495s 972ms/step - loss: 15.9519 - val_loss: 13.3987\n",
      "Epoch 117/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 15.4037 - val_loss: 14.0884\n",
      "Epoch 118/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 15.3744 - val_loss: 13.2858\n",
      "Epoch 119/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 15.6940 - val_loss: 14.0065\n",
      "Epoch 120/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 15.2343 - val_loss: 13.3199\n",
      "Epoch 121/1000\n",
      "510/510 [==============================] - 495s 972ms/step - loss: 15.3222 - val_loss: 13.1776\n",
      "Epoch 122/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 15.0037 - val_loss: 14.1487\n",
      "Epoch 123/1000\n",
      "510/510 [==============================] - 496s 972ms/step - loss: 15.2010 - val_loss: 13.5899\n",
      "Epoch 124/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 14.9093 - val_loss: 12.3729\n",
      "Epoch 125/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 15.5182 - val_loss: 12.4725\n",
      "Epoch 126/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 15.0502 - val_loss: 13.7391\n",
      "Epoch 127/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 14.9773 - val_loss: 12.2715\n",
      "Epoch 128/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 14.7127 - val_loss: 14.9078\n",
      "Epoch 129/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 14.6671 - val_loss: 13.9699\n",
      "Epoch 130/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 14.5620 - val_loss: 13.7154\n",
      "Epoch 131/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 14.2056 - val_loss: 13.4277\n",
      "Epoch 132/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 14.5721 - val_loss: 12.1979\n",
      "Epoch 133/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 14.6517 - val_loss: 11.6972\n",
      "Epoch 134/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 14.5903 - val_loss: 13.4639\n",
      "Epoch 135/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 14.6221 - val_loss: 13.8125\n",
      "Epoch 136/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 14.4304 - val_loss: 12.3464\n",
      "Epoch 137/1000\n",
      "510/510 [==============================] - 496s 972ms/step - loss: 14.4044 - val_loss: 13.1658\n",
      "Epoch 138/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 14.6570 - val_loss: 12.9208\n",
      "Epoch 139/1000\n",
      "510/510 [==============================] - 495s 972ms/step - loss: 14.4299 - val_loss: 13.4797\n",
      "Epoch 140/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 13.8944 - val_loss: 13.0643\n",
      "Epoch 141/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 13.9681 - val_loss: 12.7682\n",
      "Epoch 142/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 13.9746 - val_loss: 11.9546\n",
      "Epoch 143/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 13.9096 - val_loss: 12.7494\n",
      "Epoch 144/1000\n",
      "510/510 [==============================] - 494s 969ms/step - loss: 14.0447 - val_loss: 12.7162\n",
      "Epoch 145/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 13.7404 - val_loss: 12.4229\n",
      "Epoch 146/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 13.7264 - val_loss: 11.9091\n",
      "Epoch 147/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 13.9330 - val_loss: 11.4590\n",
      "Epoch 148/1000\n",
      "510/510 [==============================] - 495s 971ms/step - loss: 13.6259 - val_loss: 12.0621\n",
      "Epoch 149/1000\n",
      "510/510 [==============================] - 495s 970ms/step - loss: 13.9045 - val_loss: 12.3044\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/510 [==============================] - 495s 970ms/step - loss: 13.6500 - val_loss: 11.5548\n",
      "Epoch 151/1000\n",
      "510/510 [==============================] - 496s 972ms/step - loss: 13.6394 - val_loss: 12.0569\n",
      "Epoch 152/1000\n",
      "510/510 [==============================] - 496s 973ms/step - loss: 13.6897 - val_loss: 13.0673\n",
      "Epoch 153/1000\n",
      "510/510 [==============================] - 497s 975ms/step - loss: 13.5304 - val_loss: 12.0864\n",
      "Epoch 154/1000\n",
      "142/510 [=======>......................] - ETA: 4:37 - loss: 12.5981"
     ]
    }
   ],
   "source": [
    "train_files = []\n",
    "train_data = []\n",
    "valid_data = []\n",
    "test_data = []\n",
    "\n",
    "output_dir = 'training_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "epochs = 1000\n",
    "\n",
    "# for thresh in [1.11, 0.05, 0.10, 0.15, 0.20]:\n",
    "# for thresh in [0.05, 0.10, 0.15, 0.20, 1.11]:\n",
    "for thresh in [0.10, 0.20]:\n",
    "    for sample_i in range(1):\n",
    "        suffix = \"%03dp\"%(np.round(100.0*thresh))\n",
    "        train_files[:] = sorted(glob.glob('./train_%s/*.npz'%suffix))\n",
    "        total_n_train = len(train_files)\n",
    "        fsuffix = \"%s_-_%02d_-_epochs_%04d\"%(suffix, sample_i, epochs)\n",
    "        print(fsuffix)\n",
    "        # test_files = sorted(glob.glob('./test/*.npz'))\n",
    "        \n",
    "        model_fname = os.path.join(output_dir, 'speed_test_model_%s.h5'%fsuffix)\n",
    "        if os.path.isfile(model_fname):\n",
    "            continue\n",
    "            \n",
    "        n_train, n_valid, n_test = int(0.8*total_n_train), int(0.19*total_n_train), int(0.01*total_n_train)\n",
    "\n",
    "        print(n_train, n_valid, n_test)\n",
    "        if bool(0):\n",
    "            train_steps = 200\n",
    "            valid_steps = 20\n",
    "            test_steps = 20\n",
    "        else:\n",
    "            train_steps = int(np.ceil(float(n_train) / float(BATCH_SIZE)))\n",
    "            valid_steps = int(np.ceil(float(n_valid) / float(BATCH_SIZE)))\n",
    "            test_steps = int(np.ceil(float(n_test) / float(BATCH_SIZE)))\n",
    "\n",
    "        train_ids = np.random.choice(total_n_train, size=n_train, replace=False)\n",
    "        avail_ids = np.setdiff1d(np.arange(total_n_train), train_ids)\n",
    "        test_ids = np.random.choice(avail_ids, size=n_test, replace=False)\n",
    "        valid_ids = np.setdiff1d(avail_ids, test_ids)\n",
    "\n",
    "        train_data[:] = [train_files[i] for i in train_ids]\n",
    "        valid_data[:] = [train_files[i] for i in valid_ids]\n",
    "        test_data[:] = [train_files[i] for i in test_ids]\n",
    "\n",
    "        train_gen = train_generator(train_data, BATCH_SIZE)\n",
    "        valid_gen = train_generator(valid_data, BATCH_SIZE)\n",
    "        test_gen = train_generator(test_data, BATCH_SIZE)\n",
    "\n",
    "        model = cnn_model()\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "        model_fname = os.path.join(output_dir, 'best_val_model_%s.h5'%fsuffix)\n",
    "        mc = ModelCheckpoint(model_fname, monitor='val_loss', \n",
    "                             mode='min', save_best_only=True)\n",
    "\n",
    "        model_fname = os.path.join(output_dir, 'best_train_model_%s.h5'%fsuffix)\n",
    "        mc = ModelCheckpoint(model_fname, monitor='loss', \n",
    "                             mode='min', save_best_only=True)\n",
    "\n",
    "#         optimizer = rmsprop(lr=0.00001)\n",
    "        optimizer = Adam(\n",
    "            lr=0.000001, \n",
    "        #         beta_1=0.9, \n",
    "        #         beta_2=0.999, \n",
    "        #         epsilon=None, \n",
    "        #         decay=0.0, \n",
    "#             amsgrad=bool(1)\n",
    "        )\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "        # test_gen = test_generator(test_files, BATCH_SIZE)\n",
    "\n",
    "        fit_log = model.fit_generator(\n",
    "            train_gen, \n",
    "            steps_per_epoch=train_steps, \n",
    "            validation_data=valid_gen,\n",
    "            validation_steps=valid_steps,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        history_fname = os.path.join(output_dir, 'train_history_dict_%s.pickle'%fsuffix)\n",
    "        with open(history_fname, 'wb') as file_pi:\n",
    "                pickle.dump(fit_log.history, file_pi)\n",
    "\n",
    "\n",
    "        model_fname = os.path.join(output_dir, 'speed_test_model_%s.h5'%fsuffix)\n",
    "        model.save(model_fname)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = plt.subplot(1, 1, 1)\n",
    "        plt.plot(fit_log.history['loss'], label='train loss')\n",
    "        plt.plot(fit_log.history['val_loss'], label='validation loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_dir, \"loss_behaviour_%s.pdf\"%fsuffix))\n",
    "        plt.show()\n",
    "\n",
    "        #scores = model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.05\n",
    "suffix = \"%03dp\"%(np.round(100.0*thresh))\n",
    "train_files[:] = sorted(glob.glob('./train_%s/*.npz'%suffix))\n",
    "total_n_train = len(train_files)\n",
    "sample_i = 0\n",
    "n_epochs = 200\n",
    "fsuffix = \"%s_-_%02d_%04d\"%(suffix, sample_i, n_epochs)\n",
    "print(fsuffix)\n",
    "# test_files = sorted(glob.glob('./test/*.npz'))\n",
    "\n",
    "n_train, n_valid, n_test = int(0.8*total_n_train), int(0.19*total_n_train), int(0.01*total_n_train)\n",
    "\n",
    "print(n_train, n_valid, n_test)\n",
    "train_steps = int(np.ceil(float(n_train) / float(BATCH_SIZE)))\n",
    "valid_steps = int(np.ceil(float(n_valid) / float(BATCH_SIZE)))\n",
    "test_steps = int(np.ceil(float(n_test) / float(BATCH_SIZE)))\n",
    "\n",
    "train_ids = np.random.choice(total_n_train, size=n_train, replace=False)\n",
    "avail_ids = np.setdiff1d(np.arange(total_n_train), train_ids)\n",
    "test_ids = np.random.choice(avail_ids, size=n_test, replace=False)\n",
    "valid_ids = np.setdiff1d(avail_ids, test_ids)\n",
    "\n",
    "train_data[:] = [train_files[i] for i in train_ids]\n",
    "valid_data[:] = [train_files[i] for i in valid_ids]\n",
    "test_data[:] = [train_files[i] for i in test_ids]\n",
    "\n",
    "train_gen = train_generator(train_data, BATCH_SIZE)\n",
    "valid_gen = train_generator(valid_data, BATCH_SIZE)\n",
    "test_gen = train_generator(test_data, BATCH_SIZE)\n",
    "\n",
    "\n",
    "output_dir = 'training_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "model_fname = os.path.join(output_dir, 'best_val_model_%s.h5'%fsuffix)\n",
    "mc = ModelCheckpoint(model_fname, monitor='val_loss', \n",
    "                     mode='min', save_best_only=True)\n",
    "\n",
    "model_fname = os.path.join(output_dir, 'best_train_model_%s.h5'%fsuffix)\n",
    "mc = ModelCheckpoint(model_fname, monitor='loss', \n",
    "                     mode='min', save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = rmsprop(lr=0.00001)\n",
    "# optimizer = Adam(\n",
    "#     lr=0.00001, \n",
    "# #         beta_1=0.9, \n",
    "# #         beta_2=0.999, \n",
    "# #         epsilon=None, \n",
    "# #         decay=0.0, \n",
    "#     amsgrad=bool(1)\n",
    "# )\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# test_gen = test_generator(test_files, BATCH_SIZE)\n",
    "\n",
    "fit_log = model.fit_generator(\n",
    "    train_gen, \n",
    "    steps_per_epoch=train_steps, \n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=valid_steps,\n",
    "    epochs=n_epochs,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "history_fname = os.path.join(output_dir, 'train_history_dict_%s.pickle'%fsuffix)\n",
    "with open(history_fname, 'wb') as file_pi:\n",
    "        pickle.dump(fit_log.history, file_pi)\n",
    "\n",
    "\n",
    "model_fname = os.path.join(output_dir, 'speed_test_model_%s.h5'%fsuffix)\n",
    "model.save(model_fname)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.plot(fit_log.history['loss'], label='train loss')\n",
    "plt.plot(fit_log.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_gen, steps=test_steps, verbose=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4782133272715977"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.plot(fit_log.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.summary())\n",
    "print(model.weights)\n",
    "# plt.figure()\n",
    "# plt.plot(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
